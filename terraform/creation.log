root@d358df8fc803:/SAFE_VOLUME/infra/terraform# time terraform apply -auto-approve

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

  # data.azurerm_public_ip.pi_k8s will be read during apply
  # (config refers to values not yet known)
 <= data "azurerm_public_ip" "pi_k8s"  {
      + allocation_method       = (known after apply)
      + domain_name_label       = (known after apply)
      + fqdn                    = (known after apply)
      + id                      = (known after apply)
      + idle_timeout_in_minutes = (known after apply)
      + ip_address              = (known after apply)
      + ip_tags                 = (known after apply)
      + ip_version              = (known after apply)
      + location                = (known after apply)
      + name                    = "pi_k8s"
      + resource_group_name     = "RG_Kubernetes"
      + reverse_fqdn            = (known after apply)
      + sku                     = (known after apply)
      + zones                   = (known after apply)

      + timeouts {
          + read = (known after apply)
        }
    }

  # azurerm_key_vault.keyvault_k8s will be created
  + resource "azurerm_key_vault" "keyvault_k8s" {
      + access_policy              = (known after apply)
      + id                         = (known after apply)
      + location                   = "westeurope"
      + name                       = "keyvaultk8s"
      + resource_group_name        = "RG_Kubernetes"
      + sku_name                   = "standard"
      + soft_delete_enabled        = (known after apply)
      + soft_delete_retention_days = 7
      + tenant_id                  = "899789dc-202f-44b4-8472-a6d40f9eb440"
      + vault_uri                  = (known after apply)

      + network_acls {
          + bypass                     = (known after apply)
          + default_action             = (known after apply)
          + ip_rules                   = (known after apply)
          + virtual_network_subnet_ids = (known after apply)
        }
    }

  # azurerm_key_vault_access_policy.keyvault_k8s_ro will be created
  + resource "azurerm_key_vault_access_policy" "keyvault_k8s_ro" {
      + certificate_permissions = [
          + "get",
          + "getissuers",
          + "list",
          + "listissuers",
        ]
      + id                      = (known after apply)
      + key_permissions         = [
          + "get",
          + "list",
        ]
      + key_vault_id            = (known after apply)
      + object_id               = (known after apply)
      + secret_permissions      = [
          + "get",
          + "list",
        ]
      + storage_permissions     = [
          + "get",
          + "getsas",
          + "list",
          + "listsas",
        ]
      + tenant_id               = "899789dc-202f-44b4-8472-a6d40f9eb440"
    }

  # azurerm_key_vault_access_policy.keyvault_k8s_rw will be created
  + resource "azurerm_key_vault_access_policy" "keyvault_k8s_rw" {
      + certificate_permissions = [
          + "create",
          + "delete",
          + "deleteissuers",
          + "get",
          + "getissuers",
          + "import",
          + "list",
          + "listissuers",
          + "managecontacts",
          + "manageissuers",
          + "purge",
          + "recover",
          + "setissuers",
          + "update",
          + "backup",
          + "restore",
        ]
      + id                      = (known after apply)
      + key_permissions         = [
          + "backup",
          + "create",
          + "decrypt",
          + "delete",
          + "encrypt",
          + "get",
          + "import",
          + "list",
          + "purge",
          + "recover",
          + "restore",
          + "sign",
          + "unwrapKey",
          + "update",
          + "verify",
          + "wrapKey",
        ]
      + key_vault_id            = (known after apply)
      + object_id               = "af6b03e0-8970-4010-a204-ed0b33702065"
      + secret_permissions      = [
          + "backup",
          + "delete",
          + "get",
          + "list",
          + "purge",
          + "recover",
          + "restore",
          + "set",
        ]
      + storage_permissions     = [
          + "backup",
          + "delete",
          + "deletesas",
          + "get",
          + "getsas",
          + "list",
          + "listsas",
          + "purge",
          + "recover",
          + "regeneratekey",
          + "restore",
          + "set",
          + "setsas",
          + "update",
        ]
      + tenant_id               = "899789dc-202f-44b4-8472-a6d40f9eb440"
    }

  # azurerm_key_vault_secret.mysql_admin_password will be created
  + resource "azurerm_key_vault_secret" "mysql_admin_password" {
      + id             = (known after apply)
      + key_vault_id   = (known after apply)
      + name           = "mysql-admin-password"
      + value          = (sensitive value)
      + version        = (known after apply)
      + versionless_id = (known after apply)
    }

  # azurerm_key_vault_secret.mysql_ghost_database will be created
  + resource "azurerm_key_vault_secret" "mysql_ghost_database" {
      + id             = (known after apply)
      + key_vault_id   = (known after apply)
      + name           = "mysql-ghost-database"
      + value          = (sensitive value)
      + version        = (known after apply)
      + versionless_id = (known after apply)
    }

  # azurerm_key_vault_secret.mysql_ghost_password will be created
  + resource "azurerm_key_vault_secret" "mysql_ghost_password" {
      + id             = (known after apply)
      + key_vault_id   = (known after apply)
      + name           = "mysql-ghost-password"
      + value          = (sensitive value)
      + version        = (known after apply)
      + versionless_id = (known after apply)
    }

  # azurerm_key_vault_secret.mysql_ghost_username will be created
  + resource "azurerm_key_vault_secret" "mysql_ghost_username" {
      + id             = (known after apply)
      + key_vault_id   = (known after apply)
      + name           = "mysql-ghost-username"
      + value          = (sensitive value)
      + version        = (known after apply)
      + versionless_id = (known after apply)
    }

  # azurerm_managed_disk.nfs[0] will be created
  + resource "azurerm_managed_disk" "nfs" {
      + create_option        = "Empty"
      + disk_iops_read_write = (known after apply)
      + disk_mbps_read_write = (known after apply)
      + disk_size_gb         = 10
      + id                   = (known after apply)
      + location             = "westeurope"
      + name                 = "vm_k8s_Node01-data"
      + resource_group_name  = "RG_Kubernetes"
      + source_uri           = (known after apply)
      + storage_account_type = "Standard_LRS"
      + tier                 = (known after apply)
    }

  # azurerm_network_interface.nic_k8s_master will be created
  + resource "azurerm_network_interface" "nic_k8s_master" {
      + applied_dns_servers           = (known after apply)
      + dns_servers                   = (known after apply)
      + enable_accelerated_networking = false
      + enable_ip_forwarding          = true
      + id                            = (known after apply)
      + internal_dns_name_label       = (known after apply)
      + internal_domain_name_suffix   = (known after apply)
      + location                      = "westeurope"
      + mac_address                   = (known after apply)
      + name                          = "Master"
      + private_ip_address            = (known after apply)
      + private_ip_addresses          = (known after apply)
      + resource_group_name           = "RG_Kubernetes"
      + tags                          = {
          + "environment" = "K8s"
          + "node"        = "Master"
        }
      + virtual_machine_id            = (known after apply)

      + ip_configuration {
          + name                          = "nic_config_master"
          + primary                       = (known after apply)
          + private_ip_address            = "192.168.1.100"
          + private_ip_address_allocation = "static"
          + private_ip_address_version    = "IPv4"
          + public_ip_address_id          = (known after apply)
          + subnet_id                     = (known after apply)
        }
    }

  # azurerm_network_interface.nic_k8s_node["Node01"] will be created
  + resource "azurerm_network_interface" "nic_k8s_node" {
      + applied_dns_servers           = (known after apply)
      + dns_servers                   = (known after apply)
      + enable_accelerated_networking = false
      + enable_ip_forwarding          = true
      + id                            = (known after apply)
      + internal_dns_name_label       = (known after apply)
      + internal_domain_name_suffix   = (known after apply)
      + location                      = "westeurope"
      + mac_address                   = (known after apply)
      + name                          = "Node01"
      + private_ip_address            = (known after apply)
      + private_ip_addresses          = (known after apply)
      + resource_group_name           = "RG_Kubernetes"
      + tags                          = {
          + "environment" = "K8s"
          + "node"        = "Worker"
        }
      + virtual_machine_id            = (known after apply)

      + ip_configuration {
          + name                          = "nic_config_Node01"
          + primary                       = (known after apply)
          + private_ip_address            = "192.168.1.101"
          + private_ip_address_allocation = "static"
          + private_ip_address_version    = "IPv4"
          + subnet_id                     = (known after apply)
        }
    }

  # azurerm_network_interface.nic_k8s_node["Node02"] will be created
  + resource "azurerm_network_interface" "nic_k8s_node" {
      + applied_dns_servers           = (known after apply)
      + dns_servers                   = (known after apply)
      + enable_accelerated_networking = false
      + enable_ip_forwarding          = true
      + id                            = (known after apply)
      + internal_dns_name_label       = (known after apply)
      + internal_domain_name_suffix   = (known after apply)
      + location                      = "westeurope"
      + mac_address                   = (known after apply)
      + name                          = "Node02"
      + private_ip_address            = (known after apply)
      + private_ip_addresses          = (known after apply)
      + resource_group_name           = "RG_Kubernetes"
      + tags                          = {
          + "environment" = "K8s"
          + "node"        = "Worker"
        }
      + virtual_machine_id            = (known after apply)

      + ip_configuration {
          + name                          = "nic_config_Node02"
          + primary                       = (known after apply)
          + private_ip_address            = "192.168.1.102"
          + private_ip_address_allocation = "static"
          + private_ip_address_version    = "IPv4"
          + subnet_id                     = (known after apply)
        }
    }

  # azurerm_network_interface_security_group_association.nic_nsg_external will be created
  + resource "azurerm_network_interface_security_group_association" "nic_nsg_external" {
      + id                        = (known after apply)
      + network_interface_id      = (known after apply)
      + network_security_group_id = (known after apply)
    }

  # azurerm_network_security_group.nsg_k8s_external will be created
  + resource "azurerm_network_security_group" "nsg_k8s_external" {
      + id                  = (known after apply)
      + location            = "westeurope"
      + name                = "nsg_k8s_external"
      + resource_group_name = "RG_Kubernetes"
      + security_rule       = [
          + {
              + access                                     = "Allow"
              + description                                = ""
              + destination_address_prefix                 = "*"
              + destination_address_prefixes               = []
              + destination_application_security_group_ids = []
              + destination_port_range                     = "22"
              + destination_port_ranges                    = []
              + direction                                  = "Inbound"
              + name                                       = "SSH"
              + priority                                   = 1001
              + protocol                                   = "Tcp"
              + source_address_prefix                      = "*"
              + source_address_prefixes                    = []
              + source_application_security_group_ids      = []
              + source_port_range                          = "*"
              + source_port_ranges                         = []
            },
          + {
              + access                                     = "Allow"
              + description                                = ""
              + destination_address_prefix                 = "*"
              + destination_address_prefixes               = []
              + destination_application_security_group_ids = []
              + destination_port_range                     = "443"
              + destination_port_ranges                    = []
              + direction                                  = "Inbound"
              + name                                       = "HTTPS"
              + priority                                   = 1022
              + protocol                                   = "Tcp"
              + source_address_prefix                      = "*"
              + source_address_prefixes                    = []
              + source_application_security_group_ids      = []
              + source_port_range                          = "*"
              + source_port_ranges                         = []
            },
          + {
              + access                                     = "Allow"
              + description                                = ""
              + destination_address_prefix                 = "*"
              + destination_address_prefixes               = []
              + destination_application_security_group_ids = []
              + destination_port_range                     = "80"
              + destination_port_ranges                    = []
              + direction                                  = "Inbound"
              + name                                       = "HTTP"
              + priority                                   = 1011
              + protocol                                   = "Tcp"
              + source_address_prefix                      = "*"
              + source_address_prefixes                    = []
              + source_application_security_group_ids      = []
              + source_port_range                          = "*"
              + source_port_ranges                         = []
            },
        ]
      + tags                = {
          + "environment" = "K8s"
        }
    }

  # azurerm_private_dns_a_record.master will be created
  + resource "azurerm_private_dns_a_record" "master" {
      + fqdn                = (known after apply)
      + id                  = (known after apply)
      + name                = "master"
      + records             = [
          + "192.168.1.100",
        ]
      + resource_group_name = "RG_Kubernetes"
      + ttl                 = 300
      + zone_name           = "k8smvilla.com"
    }

  # azurerm_private_dns_a_record.node["Node01"] will be created
  + resource "azurerm_private_dns_a_record" "node" {
      + fqdn                = (known after apply)
      + id                  = (known after apply)
      + name                = "node01"
      + records             = [
          + "192.168.1.101",
        ]
      + resource_group_name = "RG_Kubernetes"
      + ttl                 = 300
      + zone_name           = "k8smvilla.com"
    }

  # azurerm_private_dns_a_record.node["Node02"] will be created
  + resource "azurerm_private_dns_a_record" "node" {
      + fqdn                = (known after apply)
      + id                  = (known after apply)
      + name                = "node02"
      + records             = [
          + "192.168.1.102",
        ]
      + resource_group_name = "RG_Kubernetes"
      + ttl                 = 300
      + zone_name           = "k8smvilla.com"
    }

  # azurerm_private_dns_cname_record.nfs[0] will be created
  + resource "azurerm_private_dns_cname_record" "nfs" {
      + fqdn                = (known after apply)
      + id                  = (known after apply)
      + name                = "nfs"
      + record              = (known after apply)
      + resource_group_name = "RG_Kubernetes"
      + ttl                 = 300
      + zone_name           = "k8smvilla.com"
    }

  # azurerm_private_dns_zone.k8s_mvilla will be created
  + resource "azurerm_private_dns_zone" "k8s_mvilla" {
      + id                                                    = (known after apply)
      + max_number_of_record_sets                             = (known after apply)
      + max_number_of_virtual_network_links                   = (known after apply)
      + max_number_of_virtual_network_links_with_registration = (known after apply)
      + name                                                  = "k8smvilla.com"
      + number_of_record_sets                                 = (known after apply)
      + resource_group_name                                   = "RG_Kubernetes"

      + soa_record {
          + email         = (known after apply)
          + expire_time   = (known after apply)
          + fqdn          = (known after apply)
          + host_name     = (known after apply)
          + minimum_ttl   = (known after apply)
          + refresh_time  = (known after apply)
          + retry_time    = (known after apply)
          + serial_number = (known after apply)
          + tags          = (known after apply)
          + ttl           = (known after apply)
        }
    }

  # azurerm_private_dns_zone_virtual_network_link.vn_dns_link will be created
  + resource "azurerm_private_dns_zone_virtual_network_link" "vn_dns_link" {
      + id                    = (known after apply)
      + name                  = "vn_dns_link"
      + private_dns_zone_name = "k8smvilla.com"
      + registration_enabled  = false
      + resource_group_name   = "RG_Kubernetes"
      + virtual_network_id    = (known after apply)
    }

  # azurerm_public_ip.pi_k8s will be created
  + resource "azurerm_public_ip" "pi_k8s" {
      + allocation_method       = "Static"
      + availability_zone       = (known after apply)
      + domain_name_label       = "ghostmvilla"
      + fqdn                    = (known after apply)
      + id                      = (known after apply)
      + idle_timeout_in_minutes = 4
      + ip_address              = (known after apply)
      + ip_version              = "IPv4"
      + location                = "westeurope"
      + name                    = "pi_k8s"
      + resource_group_name     = "RG_Kubernetes"
      + sku                     = "Standard"
      + tags                    = {
          + "environment" = "K8s"
        }
      + zones                   = (known after apply)
    }

  # azurerm_resource_group.rg_k8s will be created
  + resource "azurerm_resource_group" "rg_k8s" {
      + id       = (known after apply)
      + location = "westeurope"
      + name     = "RG_Kubernetes"
      + tags     = {
          + "environment" = "K8s"
        }
    }

  # azurerm_storage_account.sa_k8s will be created
  + resource "azurerm_storage_account" "sa_k8s" {
      + access_tier                      = (known after apply)
      + account_kind                     = "StorageV2"
      + account_replication_type         = "LRS"
      + account_tier                     = "Standard"
      + allow_blob_public_access         = false
      + enable_https_traffic_only        = true
      + id                               = (known after apply)
      + is_hns_enabled                   = false
      + large_file_share_enabled         = (known after apply)
      + location                         = "westeurope"
      + min_tls_version                  = "TLS1_0"
      + name                             = "mvillasa"
      + nfsv3_enabled                    = false
      + primary_access_key               = (sensitive value)
      + primary_blob_connection_string   = (sensitive value)
      + primary_blob_endpoint            = (known after apply)
      + primary_blob_host                = (known after apply)
      + primary_connection_string        = (sensitive value)
      + primary_dfs_endpoint             = (known after apply)
      + primary_dfs_host                 = (known after apply)
      + primary_file_endpoint            = (known after apply)
      + primary_file_host                = (known after apply)
      + primary_location                 = (known after apply)
      + primary_queue_endpoint           = (known after apply)
      + primary_queue_host               = (known after apply)
      + primary_table_endpoint           = (known after apply)
      + primary_table_host               = (known after apply)
      + primary_web_endpoint             = (known after apply)
      + primary_web_host                 = (known after apply)
      + resource_group_name              = "RG_Kubernetes"
      + secondary_access_key             = (sensitive value)
      + secondary_blob_connection_string = (sensitive value)
      + secondary_blob_endpoint          = (known after apply)
      + secondary_blob_host              = (known after apply)
      + secondary_connection_string      = (sensitive value)
      + secondary_dfs_endpoint           = (known after apply)
      + secondary_dfs_host               = (known after apply)
      + secondary_file_endpoint          = (known after apply)
      + secondary_file_host              = (known after apply)
      + secondary_location               = (known after apply)
      + secondary_queue_endpoint         = (known after apply)
      + secondary_queue_host             = (known after apply)
      + secondary_table_endpoint         = (known after apply)
      + secondary_table_host             = (known after apply)
      + secondary_web_endpoint           = (known after apply)
      + secondary_web_host               = (known after apply)
      + tags                             = {
          + "environment" = "K8s"
        }

      + blob_properties {
          + change_feed_enabled      = (known after apply)
          + default_service_version  = (known after apply)
          + last_access_time_enabled = (known after apply)
          + versioning_enabled       = (known after apply)

          + container_delete_retention_policy {
              + days = (known after apply)
            }

          + cors_rule {
              + allowed_headers    = (known after apply)
              + allowed_methods    = (known after apply)
              + allowed_origins    = (known after apply)
              + exposed_headers    = (known after apply)
              + max_age_in_seconds = (known after apply)
            }

          + delete_retention_policy {
              + days = (known after apply)
            }
        }

      + identity {
          + identity_ids = (known after apply)
          + principal_id = (known after apply)
          + tenant_id    = (known after apply)
          + type         = (known after apply)
        }

      + network_rules {
          + bypass                     = (known after apply)
          + default_action             = (known after apply)
          + ip_rules                   = (known after apply)
          + virtual_network_subnet_ids = (known after apply)

          + private_link_access {
              + endpoint_resource_id = (known after apply)
              + endpoint_tenant_id   = (known after apply)
            }
        }

      + queue_properties {
          + cors_rule {
              + allowed_headers    = (known after apply)
              + allowed_methods    = (known after apply)
              + allowed_origins    = (known after apply)
              + exposed_headers    = (known after apply)
              + max_age_in_seconds = (known after apply)
            }

          + hour_metrics {
              + enabled               = (known after apply)
              + include_apis          = (known after apply)
              + retention_policy_days = (known after apply)
              + version               = (known after apply)
            }

          + logging {
              + delete                = (known after apply)
              + read                  = (known after apply)
              + retention_policy_days = (known after apply)
              + version               = (known after apply)
              + write                 = (known after apply)
            }

          + minute_metrics {
              + enabled               = (known after apply)
              + include_apis          = (known after apply)
              + retention_policy_days = (known after apply)
              + version               = (known after apply)
            }
        }

      + routing {
          + choice                      = (known after apply)
          + publish_internet_endpoints  = (known after apply)
          + publish_microsoft_endpoints = (known after apply)
        }

      + share_properties {
          + cors_rule {
              + allowed_headers    = (known after apply)
              + allowed_methods    = (known after apply)
              + allowed_origins    = (known after apply)
              + exposed_headers    = (known after apply)
              + max_age_in_seconds = (known after apply)
            }

          + retention_policy {
              + days = (known after apply)
            }

          + smb {
              + authentication_types            = (known after apply)
              + channel_encryption_type         = (known after apply)
              + kerberos_ticket_encryption_type = (known after apply)
              + versions                        = (known after apply)
            }
        }
    }

  # azurerm_subnet.sn_k8s_private will be created
  + resource "azurerm_subnet" "sn_k8s_private" {
      + address_prefix                                 = (known after apply)
      + address_prefixes                               = [
          + "192.168.1.0/24",
        ]
      + enforce_private_link_endpoint_network_policies = false
      + enforce_private_link_service_network_policies  = false
      + id                                             = (known after apply)
      + name                                           = "sn_k8s_private"
      + resource_group_name                            = "RG_Kubernetes"
      + virtual_network_name                           = "vn_k8s"
    }

  # azurerm_virtual_machine.vm_k8s_master will be created
  + resource "azurerm_virtual_machine" "vm_k8s_master" {
      + availability_set_id              = (known after apply)
      + delete_data_disks_on_termination = false
      + delete_os_disk_on_termination    = true
      + id                               = (known after apply)
      + license_type                     = (known after apply)
      + location                         = "westeurope"
      + name                             = "vm_k8s_master"
      + network_interface_ids            = (known after apply)
      + primary_network_interface_id     = (known after apply)
      + resource_group_name              = "RG_Kubernetes"
      + tags                             = {
          + "environment" = "K8s"
          + "node"        = "Master"
        }
      + vm_size                          = "Standard_A2_v2"

      + boot_diagnostics {
          + enabled     = true
          + storage_uri = (known after apply)
        }

      + identity {
          + principal_id = (known after apply)
          + type         = "SystemAssigned"
        }

      + os_profile {
          + admin_username = "azureuser"
          + computer_name  = "Master"
          + custom_data    = (known after apply)
        }

      + os_profile_linux_config {
          + disable_password_authentication = true

          + ssh_keys {
              + key_data = <<-EOT
                    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDD0LdZ8/TNMJtngp9G4hRSFiVvG+vfuZSn9KxrVhNyY2zV93gWt2pQpDbceUzkMy4ba5rOk0eWn8D9tTHuOsE27/Z15rfuagZ5t0HuCY3yi3MASlvaV0VR/t0BIQtcYHxifWsl8/vPCPLLCJEyF2FUY24Qk9JMYq4Ednw6ncC9PySy/K918E6FASZTsivqoG1Otcrp2bUIlHjb77NuAYdlVjtVJcPPxc0qRYW87AgJOUVVpHHLyWJgLOgZmWF8ZiYVH2ooDEafwentgnJiHsZ3ujbruqP5LlOMPFHDK4lpUHtlYj00xo6a++b7PtKmDZKY4K0eXqOdx7SYX2FvRmjj root@5579f537dd67
                EOT
              + path     = "/home/azureuser/.ssh/authorized_keys"
            }
        }

      + storage_data_disk {
          + caching                   = (known after apply)
          + create_option             = (known after apply)
          + disk_size_gb              = (known after apply)
          + lun                       = (known after apply)
          + managed_disk_id           = (known after apply)
          + managed_disk_type         = (known after apply)
          + name                      = (known after apply)
          + vhd_uri                   = (known after apply)
          + write_accelerator_enabled = (known after apply)
        }

      + storage_image_reference {
          + offer     = "debian-10"
          + publisher = "Debian"
          + sku       = "10"
          + version   = "latest"
        }

      + storage_os_disk {
          + caching                   = "ReadWrite"
          + create_option             = "FromImage"
          + disk_size_gb              = (known after apply)
          + managed_disk_id           = (known after apply)
          + managed_disk_type         = "Standard_LRS"
          + name                      = "K8s_Master_OS"
          + os_type                   = (known after apply)
          + write_accelerator_enabled = false
        }
    }

  # azurerm_virtual_machine.vm_k8s_node["Node01"] will be created
  + resource "azurerm_virtual_machine" "vm_k8s_node" {
      + availability_set_id              = (known after apply)
      + delete_data_disks_on_termination = false
      + delete_os_disk_on_termination    = true
      + id                               = (known after apply)
      + license_type                     = (known after apply)
      + location                         = "westeurope"
      + name                             = "vm_k8s_Node01"
      + network_interface_ids            = (known after apply)
      + primary_network_interface_id     = (known after apply)
      + resource_group_name              = "RG_Kubernetes"
      + tags                             = {
          + "environment" = "K8s"
          + "node"        = "Worker"
        }
      + vm_size                          = "Standard_A1_v2"

      + boot_diagnostics {
          + enabled     = true
          + storage_uri = (known after apply)
        }

      + identity {
          + identity_ids = (known after apply)
          + principal_id = (known after apply)
          + type         = (known after apply)
        }

      + os_profile {
          + admin_username = "azureuser"
          + computer_name  = "Node01"
          + custom_data    = (known after apply)
        }

      + os_profile_linux_config {
          + disable_password_authentication = true

          + ssh_keys {
              + key_data = <<-EOT
                    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDD0LdZ8/TNMJtngp9G4hRSFiVvG+vfuZSn9KxrVhNyY2zV93gWt2pQpDbceUzkMy4ba5rOk0eWn8D9tTHuOsE27/Z15rfuagZ5t0HuCY3yi3MASlvaV0VR/t0BIQtcYHxifWsl8/vPCPLLCJEyF2FUY24Qk9JMYq4Ednw6ncC9PySy/K918E6FASZTsivqoG1Otcrp2bUIlHjb77NuAYdlVjtVJcPPxc0qRYW87AgJOUVVpHHLyWJgLOgZmWF8ZiYVH2ooDEafwentgnJiHsZ3ujbruqP5LlOMPFHDK4lpUHtlYj00xo6a++b7PtKmDZKY4K0eXqOdx7SYX2FvRmjj root@5579f537dd67
                EOT
              + path     = "/home/azureuser/.ssh/authorized_keys"
            }
        }

      + storage_data_disk {
          + caching                   = (known after apply)
          + create_option             = (known after apply)
          + disk_size_gb              = (known after apply)
          + lun                       = (known after apply)
          + managed_disk_id           = (known after apply)
          + managed_disk_type         = (known after apply)
          + name                      = (known after apply)
          + vhd_uri                   = (known after apply)
          + write_accelerator_enabled = (known after apply)
        }

      + storage_image_reference {
          + offer     = "debian-10"
          + publisher = "Debian"
          + sku       = "10"
          + version   = "latest"
        }

      + storage_os_disk {
          + caching                   = "ReadWrite"
          + create_option             = "FromImage"
          + disk_size_gb              = (known after apply)
          + managed_disk_id           = (known after apply)
          + managed_disk_type         = "Standard_LRS"
          + name                      = "K8s_Node01_OS"
          + os_type                   = (known after apply)
          + write_accelerator_enabled = false
        }
    }

  # azurerm_virtual_machine.vm_k8s_node["Node02"] will be created
  + resource "azurerm_virtual_machine" "vm_k8s_node" {
      + availability_set_id              = (known after apply)
      + delete_data_disks_on_termination = false
      + delete_os_disk_on_termination    = true
      + id                               = (known after apply)
      + license_type                     = (known after apply)
      + location                         = "westeurope"
      + name                             = "vm_k8s_Node02"
      + network_interface_ids            = (known after apply)
      + primary_network_interface_id     = (known after apply)
      + resource_group_name              = "RG_Kubernetes"
      + tags                             = {
          + "environment" = "K8s"
          + "node"        = "Worker"
        }
      + vm_size                          = "Standard_A1_v2"

      + boot_diagnostics {
          + enabled     = true
          + storage_uri = (known after apply)
        }

      + identity {
          + identity_ids = (known after apply)
          + principal_id = (known after apply)
          + type         = (known after apply)
        }

      + os_profile {
          + admin_username = "azureuser"
          + computer_name  = "Node02"
          + custom_data    = (known after apply)
        }

      + os_profile_linux_config {
          + disable_password_authentication = true

          + ssh_keys {
              + key_data = <<-EOT
                    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDD0LdZ8/TNMJtngp9G4hRSFiVvG+vfuZSn9KxrVhNyY2zV93gWt2pQpDbceUzkMy4ba5rOk0eWn8D9tTHuOsE27/Z15rfuagZ5t0HuCY3yi3MASlvaV0VR/t0BIQtcYHxifWsl8/vPCPLLCJEyF2FUY24Qk9JMYq4Ednw6ncC9PySy/K918E6FASZTsivqoG1Otcrp2bUIlHjb77NuAYdlVjtVJcPPxc0qRYW87AgJOUVVpHHLyWJgLOgZmWF8ZiYVH2ooDEafwentgnJiHsZ3ujbruqP5LlOMPFHDK4lpUHtlYj00xo6a++b7PtKmDZKY4K0eXqOdx7SYX2FvRmjj root@5579f537dd67
                EOT
              + path     = "/home/azureuser/.ssh/authorized_keys"
            }
        }

      + storage_data_disk {
          + caching                   = (known after apply)
          + create_option             = (known after apply)
          + disk_size_gb              = (known after apply)
          + lun                       = (known after apply)
          + managed_disk_id           = (known after apply)
          + managed_disk_type         = (known after apply)
          + name                      = (known after apply)
          + vhd_uri                   = (known after apply)
          + write_accelerator_enabled = (known after apply)
        }

      + storage_image_reference {
          + offer     = "debian-10"
          + publisher = "Debian"
          + sku       = "10"
          + version   = "latest"
        }

      + storage_os_disk {
          + caching                   = "ReadWrite"
          + create_option             = "FromImage"
          + disk_size_gb              = (known after apply)
          + managed_disk_id           = (known after apply)
          + managed_disk_type         = "Standard_LRS"
          + name                      = "K8s_Node02_OS"
          + os_type                   = (known after apply)
          + write_accelerator_enabled = false
        }
    }

  # azurerm_virtual_machine_data_disk_attachment.nfs[0] will be created
  + resource "azurerm_virtual_machine_data_disk_attachment" "nfs" {
      + caching                   = "ReadWrite"
      + create_option             = "Attach"
      + id                        = (known after apply)
      + lun                       = 10
      + managed_disk_id           = (known after apply)
      + virtual_machine_id        = (known after apply)
      + write_accelerator_enabled = false
    }

  # azurerm_virtual_network.vn_k8s will be created
  + resource "azurerm_virtual_network" "vn_k8s" {
      + address_space         = [
          + "192.168.0.0/16",
        ]
      + guid                  = (known after apply)
      + id                    = (known after apply)
      + location              = "westeurope"
      + name                  = "vn_k8s"
      + resource_group_name   = "RG_Kubernetes"
      + subnet                = (known after apply)
      + tags                  = {
          + "environment" = "K8s"
        }
      + vm_protection_enabled = false
    }

  # null_resource.ansible will be created
  + resource "null_resource" "ansible" {
      + id = (known after apply)
    }

  # random_id.randomId will be created
  + resource "random_id" "randomId" {
      + b64_std     = (known after apply)
      + b64_url     = (known after apply)
      + byte_length = 8
      + dec         = (known after apply)
      + hex         = (known after apply)
      + id          = (known after apply)
      + keepers     = {
          + "resource_group" = "RG_Kubernetes"
        }
    }

  # random_string.mysql_admin_password will be created
  + resource "random_string" "mysql_admin_password" {
      + id               = (known after apply)
      + length           = 18
      + lower            = true
      + min_lower        = 2
      + min_numeric      = 2
      + min_special      = 2
      + min_upper        = 2
      + number           = true
      + override_special = "/@-.,_"
      + result           = (known after apply)
      + special          = true
      + upper            = true
    }

  # random_string.mysql_ghost_password will be created
  + resource "random_string" "mysql_ghost_password" {
      + id               = (known after apply)
      + length           = 18
      + lower            = true
      + min_lower        = 2
      + min_numeric      = 2
      + min_special      = 2
      + min_upper        = 2
      + number           = true
      + override_special = "/@-.,_"
      + result           = (known after apply)
      + special          = true
      + upper            = true
    }

  # random_string.mysql_ghost_username will be created
  + resource "random_string" "mysql_ghost_username" {
      + id          = (known after apply)
      + length      = 8
      + lower       = true
      + min_lower   = 2
      + min_numeric = 2
      + min_special = 0
      + min_upper   = 2
      + number      = true
      + result      = (known after apply)
      + special     = false
      + upper       = true
    }

  # tls_private_key.external_ssh will be created
  + resource "tls_private_key" "external_ssh" {
      + algorithm                  = "RSA"
      + ecdsa_curve                = "P224"
      + id                         = (known after apply)
      + private_key_pem            = (sensitive value)
      + public_key_fingerprint_md5 = (known after apply)
      + public_key_openssh         = (known after apply)
      + public_key_pem             = (known after apply)
      + rsa_bits                   = 4096
    }

  # tls_private_key.internal_ssh will be created
  + resource "tls_private_key" "internal_ssh" {
      + algorithm                  = "RSA"
      + ecdsa_curve                = "P224"
      + id                         = (known after apply)
      + private_key_pem            = (sensitive value)
      + public_key_fingerprint_md5 = (known after apply)
      + public_key_openssh         = (known after apply)
      + public_key_pem             = (known after apply)
      + rsa_bits                   = 4096
    }

Plan: 35 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + ansible_exec_command    = (known after apply)
  + ghost_http_service_url  = (known after apply)
  + ghost_https_service_url = (known after apply)
  + master_private_address  = (known after apply)
  + master_public_address   = (known after apply)
  + node01_private_address  = (known after apply)
  + node02_private_address  = (known after apply)
  + ssh_admin_user          = "azureuser"
  + ssh_master_connection   = (known after apply)
  + ssh_node01_connection   = (known after apply)
  + ssh_node02_connection   = (known after apply)
  + subnet_cidr_private     = [
      + "192.168.1.0/24",
    ]
  + virtual_network_cidr    = [
      + "192.168.0.0/16",
    ]
random_string.mysql_ghost_password: Creating...
random_string.mysql_admin_password: Creating...
random_string.mysql_ghost_username: Creating...
tls_private_key.external_ssh: Creating...
random_string.mysql_ghost_password: Creation complete after 0s [id=0_FcWn2.KBPh6DUHJN]
random_string.mysql_ghost_username: Creation complete after 0s [id=wR50UL1j]
tls_private_key.internal_ssh: Creating...
random_string.mysql_admin_password: Creation complete after 0s [id=EDo1gc_,GTm1_J7MXU]
tls_private_key.external_ssh: Creation complete after 1s [id=cbccc9d3205770fe0d7f562e8e8a8a9b985d9caf]
tls_private_key.internal_ssh: Creation complete after 4s [id=eaf4f1214e375885309578b9a894d86046d0b1bd]
azurerm_resource_group.rg_k8s: Creating...
azurerm_resource_group.rg_k8s: Creation complete after 1s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes]
random_id.randomId: Creating...
random_id.randomId: Creation complete after 0s [id=6rkPO8OF_dg]
azurerm_private_dns_zone.k8s_mvilla: Creating...
azurerm_public_ip.pi_k8s: Creating...
azurerm_virtual_network.vn_k8s: Creating...
azurerm_key_vault.keyvault_k8s: Creating...
azurerm_network_security_group.nsg_k8s_external: Creating...
azurerm_storage_account.sa_k8s: Creating...
azurerm_virtual_network.vn_k8s: Creation complete after 5s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/virtualNetworks/vn_k8s]
azurerm_subnet.sn_k8s_private: Creating...
azurerm_network_security_group.nsg_k8s_external: Creation complete after 5s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/networkSecurityGroups/nsg_k8s_external]
azurerm_public_ip.pi_k8s: Creation complete after 8s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/publicIPAddresses/pi_k8s]
azurerm_subnet.sn_k8s_private: Creation complete after 4s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/virtualNetworks/vn_k8s/subnets/sn_k8s_private]
azurerm_network_interface.nic_k8s_master: Creating...
azurerm_network_interface.nic_k8s_node["Node01"]: Creating...
azurerm_network_interface.nic_k8s_node["Node02"]: Creating...
azurerm_private_dns_zone.k8s_mvilla: Still creating... [10s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [10s elapsed]
azurerm_storage_account.sa_k8s: Still creating... [10s elapsed]
azurerm_network_interface.nic_k8s_master: Creation complete after 2s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/networkInterfaces/Master]
azurerm_network_interface_security_group_association.nic_nsg_external: Creating...
azurerm_network_interface.nic_k8s_node["Node01"]: Creation complete after 3s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/networkInterfaces/Node01]
azurerm_network_interface_security_group_association.nic_nsg_external: Creation complete after 1s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/networkInterfaces/Master|/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/networkSecurityGroups/nsg_k8s_external]
azurerm_network_interface.nic_k8s_node["Node02"]: Creation complete after 4s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/networkInterfaces/Node02]
azurerm_private_dns_zone.k8s_mvilla: Still creating... [20s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [20s elapsed]
azurerm_storage_account.sa_k8s: Still creating... [20s elapsed]
azurerm_storage_account.sa_k8s: Creation complete after 25s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Storage/storageAccounts/mvillasa]
azurerm_virtual_machine.vm_k8s_master: Creating...
azurerm_virtual_machine.vm_k8s_node["Node01"]: Creating...
azurerm_virtual_machine.vm_k8s_node["Node02"]: Creating...
azurerm_private_dns_zone.k8s_mvilla: Still creating... [30s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [30s elapsed]
azurerm_private_dns_zone.k8s_mvilla: Creation complete after 33s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/privateDnsZones/k8smvilla.com]
azurerm_private_dns_a_record.node["Node01"]: Creating...
azurerm_private_dns_a_record.node["Node02"]: Creating...
azurerm_private_dns_a_record.master: Creating...
azurerm_private_dns_zone_virtual_network_link.vn_dns_link: Creating...
azurerm_private_dns_a_record.node["Node02"]: Creation complete after 2s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/privateDnsZones/k8smvilla.com/A/node02]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [10s elapsed]
azurerm_virtual_machine.vm_k8s_master: Still creating... [10s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node02"]: Still creating... [10s elapsed]
azurerm_private_dns_a_record.node["Node01"]: Creation complete after 2s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/privateDnsZones/k8smvilla.com/A/node01]
azurerm_private_dns_cname_record.nfs[0]: Creating...
azurerm_private_dns_a_record.master: Creation complete after 2s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/privateDnsZones/k8smvilla.com/A/master]
azurerm_private_dns_cname_record.nfs[0]: Creation complete after 1s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/privateDnsZones/k8smvilla.com/CNAME/nfs]
azurerm_key_vault.keyvault_k8s: Still creating... [40s elapsed]
azurerm_private_dns_zone_virtual_network_link.vn_dns_link: Still creating... [10s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node02"]: Still creating... [20s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [20s elapsed]
azurerm_virtual_machine.vm_k8s_master: Still creating... [20s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [50s elapsed]
azurerm_private_dns_zone_virtual_network_link.vn_dns_link: Still creating... [20s elapsed]
azurerm_virtual_machine.vm_k8s_master: Still creating... [30s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node02"]: Still creating... [30s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [30s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [1m0s elapsed]
azurerm_private_dns_zone_virtual_network_link.vn_dns_link: Still creating... [30s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [40s elapsed]
azurerm_virtual_machine.vm_k8s_master: Still creating... [40s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node02"]: Still creating... [40s elapsed]
azurerm_private_dns_zone_virtual_network_link.vn_dns_link: Creation complete after 33s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/privateDnsZones/k8smvilla.com/virtualNetworkLinks/vn_dns_link]
azurerm_key_vault.keyvault_k8s: Still creating... [1m10s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node02"]: Creation complete after 48s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Compute/virtualMachines/vm_k8s_Node02]
azurerm_virtual_machine.vm_k8s_master: Creation complete after 49s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Compute/virtualMachines/vm_k8s_master]
data.azurerm_public_ip.pi_k8s: Reading...
data.azurerm_public_ip.pi_k8s: Read complete after 0s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Network/publicIPAddresses/pi_k8s]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [50s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [1m20s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [1m0s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [1m30s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [1m10s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [1m40s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [1m20s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [1m50s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [1m30s elapsed]
azurerm_key_vault.keyvault_k8s: Still creating... [2m0s elapsed]
azurerm_virtual_machine.vm_k8s_node["Node01"]: Still creating... [1m40s elapsed]
azurerm_key_vault.keyvault_k8s: Creation complete after 2m10s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.KeyVault/vaults/keyvaultk8s]
azurerm_key_vault_access_policy.keyvault_k8s_ro: Creating...
azurerm_key_vault_access_policy.keyvault_k8s_rw: Creating...
azurerm_virtual_machine.vm_k8s_node["Node01"]: Creation complete after 1m48s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Compute/virtualMachines/vm_k8s_Node01]
azurerm_managed_disk.nfs[0]: Creating...
azurerm_managed_disk.nfs[0]: Creation complete after 4s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Compute/disks/vm_k8s_Node01-data]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Creating...
azurerm_key_vault_access_policy.keyvault_k8s_rw: Creation complete after 7s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.KeyVault/vaults/keyvaultk8s/objectId/af6b03e0-8970-4010-a204-ed0b33702065]
azurerm_key_vault_access_policy.keyvault_k8s_ro: Still creating... [10s elapsed]
azurerm_key_vault_access_policy.keyvault_k8s_ro: Creation complete after 13s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.KeyVault/vaults/keyvaultk8s/objectId/a1a96b92-7d89-4817-95bd-d11f5cfd9e40]
azurerm_key_vault_secret.mysql_admin_password: Creating...
azurerm_key_vault_secret.mysql_ghost_username: Creating...
azurerm_key_vault_secret.mysql_ghost_password: Creating...
azurerm_key_vault_secret.mysql_ghost_database: Creating...
azurerm_key_vault_secret.mysql_admin_password: Creation complete after 2s [id=https://keyvaultk8s.vault.azure.net/secrets/mysql-admin-password/a21fbdc74e9c4b8084fe03854fe634f1]
azurerm_key_vault_secret.mysql_ghost_username: Creation complete after 2s [id=https://keyvaultk8s.vault.azure.net/secrets/mysql-ghost-username/b9136eab78234836983e980b7c856955]
azurerm_key_vault_secret.mysql_ghost_database: Creation complete after 3s [id=https://keyvaultk8s.vault.azure.net/secrets/mysql-ghost-database/2608a84a2f864243a3880cc3bee3f3ed]
azurerm_key_vault_secret.mysql_ghost_password: Creation complete after 3s [id=https://keyvaultk8s.vault.azure.net/secrets/mysql-ghost-password/a7a807d0ce8d401d812710c736fa81e0]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Still creating... [10s elapsed]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Still creating... [20s elapsed]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Still creating... [30s elapsed]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Still creating... [40s elapsed]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Still creating... [50s elapsed]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Still creating... [1m0s elapsed]
azurerm_virtual_machine_data_disk_attachment.nfs[0]: Creation complete after 1m1s [id=/subscriptions/fa4d5daf-6219-4ac5-8718-a1ff86d3fca7/resourceGroups/RG_Kubernetes/providers/Microsoft.Compute/virtualMachines/vm_k8s_Node01/dataDisks/vm_k8s_Node01-data]
null_resource.ansible: Creating...
null_resource.ansible: Provisioning with 'local-exec'...
null_resource.ansible (local-exec): Executing: ["/bin/sh" "-c" "ansible-playbook -i ../ansible/hosts -e jump_host='20.93.250.89' -e admin_user='azureuser' -e subnet_cidr_private='192.168.1.0/24' -e private_lan_master='192.168.1.100' -e private_lan_node01='192.168.1.101' -e private_lan_node02='192.168.1.102' -e internal_private_key_file='~/.ssh/test.pem' -e external_private_key_file='~/.ssh/test.pem' -e ghost_url='ghostmvilla.westeurope.cloudapp.azure.com' ../ansible/playbook.yml"]
null_resource.ansible (local-exec): [DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
null_resource.ansible (local-exec): controller starting with Ansible 2.12. Current version: 3.7.3 (default, Jan 22
null_resource.ansible (local-exec): 2021, 20:04:44) [GCC 8.3.0]. This feature will be removed from ansible-core in
null_resource.ansible (local-exec): version 2.12. Deprecation warnings can be disabled by setting
null_resource.ansible (local-exec): deprecation_warnings=False in ansible.cfg.

null_resource.ansible (local-exec): PLAY [all] *********************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible (local-exec): [DEPRECATION WARNING]: Distribution debian 10.9 on host Master should use
null_resource.ansible (local-exec): /usr/bin/python3, but is using /usr/bin/python for backward compatibility with
null_resource.ansible (local-exec): prior Ansible releases. A future Ansible release will default to using the
null_resource.ansible (local-exec): discovered platform python for this host. See https://docs.ansible.com/ansible/
null_resource.ansible (local-exec): 2.11/reference_appendices/interpreter_discovery.html for more information. This
null_resource.ansible (local-exec):  feature will be removed in version 2.12. Deprecation warnings can be disabled
null_resource.ansible (local-exec): by setting deprecation_warnings=False in ansible.cfg.
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): [DEPRECATION WARNING]: Distribution debian 10.9 on host Node01 should use
null_resource.ansible (local-exec): /usr/bin/python3, but is using /usr/bin/python for backward compatibility with
null_resource.ansible (local-exec): prior Ansible releases. A future Ansible release will default to using the
null_resource.ansible (local-exec): discovered platform python for this host. See https://docs.ansible.com/ansible/
null_resource.ansible (local-exec): 2.11/reference_appendices/interpreter_discovery.html for more information. This
null_resource.ansible (local-exec):  feature will be removed in version 2.12. Deprecation warnings can be disabled
null_resource.ansible (local-exec): by setting deprecation_warnings=False in ansible.cfg.
null_resource.ansible (local-exec): ok: [Node01]
null_resource.ansible (local-exec): [DEPRECATION WARNING]: Distribution debian 10.9 on host Node02 should use
null_resource.ansible (local-exec): /usr/bin/python3, but is using /usr/bin/python for backward compatibility with
null_resource.ansible (local-exec): prior Ansible releases. A future Ansible release will default to using the
null_resource.ansible (local-exec): discovered platform python for this host. See https://docs.ansible.com/ansible/
null_resource.ansible (local-exec): 2.11/reference_appendices/interpreter_discovery.html for more information. This
null_resource.ansible (local-exec):  feature will be removed in version 2.12. Deprecation warnings can be disabled
null_resource.ansible (local-exec): by setting deprecation_warnings=False in ansible.cfg.
null_resource.ansible (local-exec): ok: [Node02]

null_resource.ansible (local-exec): TASK [common : Correct python version to always execute python3] ***************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible: Still creating... [10s elapsed]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [common : Update apt repository cache] ************************************
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node01]
null_resource.ansible (local-exec): ok: [Node02]

null_resource.ansible (local-exec): TASK [common : Install Common packages] ****************************************
null_resource.ansible: Still creating... [20s elapsed]
null_resource.ansible: Still creating... [30s elapsed]
null_resource.ansible: Still creating... [40s elapsed]
null_resource.ansible: Still creating... [50s elapsed]
null_resource.ansible: Still creating... [1m0s elapsed]
null_resource.ansible: Still creating... [1m10s elapsed]
null_resource.ansible: Still creating... [1m20s elapsed]
null_resource.ansible: Still creating... [1m30s elapsed]
null_resource.ansible: Still creating... [1m40s elapsed]
null_resource.ansible: Still creating... [1m50s elapsed]
null_resource.ansible: Still creating... [2m0s elapsed]
null_resource.ansible: Still creating... [2m10s elapsed]
null_resource.ansible: Still creating... [2m20s elapsed]
null_resource.ansible: Still creating... [2m30s elapsed]
null_resource.ansible: Still creating... [2m40s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible: Still creating... [2m50s elapsed]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [common : Install pip packages] *******************************************
null_resource.ansible: Still creating... [3m0s elapsed]
null_resource.ansible: Still creating... [3m10s elapsed]
null_resource.ansible: Still creating... [3m20s elapsed]
null_resource.ansible: Still creating... [3m30s elapsed]
null_resource.ansible: Still creating... [3m40s elapsed]
null_resource.ansible: Still creating... [3m50s elapsed]
null_resource.ansible: Still creating... [4m0s elapsed]
null_resource.ansible: Still creating... [4m10s elapsed]
null_resource.ansible: Still creating... [4m20s elapsed]
null_resource.ansible: Still creating... [4m30s elapsed]
null_resource.ansible: Still creating... [4m40s elapsed]
null_resource.ansible: Still creating... [4m50s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible: Still creating... [5m0s elapsed]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible: Still creating... [5m10s elapsed]
null_resource.ansible: Still creating... [5m20s elapsed]
null_resource.ansible: Still creating... [5m30s elapsed]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [common : Set vim as default editor] **************************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [common : Set timezone to Europe/Madrid] **********************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [common : Enable Chrony service] ******************************************
null_resource.ansible: Still creating... [5m40s elapsed]
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node02]
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): TASK [common : Ensure Chrony service is running] *******************************
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node02]
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): PLAY [nfs] *********************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Make sure mount point exists] **************************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Install LVM and NFS packages] **************************************
null_resource.ansible: Still creating... [5m50s elapsed]
null_resource.ansible: Still creating... [6m0s elapsed]
null_resource.ansible: Still creating... [6m10s elapsed]
null_resource.ansible: Still creating... [6m20s elapsed]
null_resource.ansible: Still creating... [6m30s elapsed]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Make NFS to run in private LAN only] *******************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Read device information] *******************************************
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Debug sdc_info] ****************************************************
null_resource.ansible (local-exec): ok: [Node01] => {
null_resource.ansible (local-exec):     "sdc_info.partitions": []
null_resource.ansible (local-exec): }

null_resource.ansible (local-exec): TASK [nfs : Create a new ext4 primary partition] *******************************
null_resource.ansible: Still creating... [6m40s elapsed]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Create Volume Group on /dev/sdc with physical extent size = 10g] ***
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Create a logical volume] *******************************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Create xfs filesystem on nfs data partition] ***********************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Make sure mount point exists] **************************************
null_resource.ansible: Still creating... [6m50s elapsed]
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Check if /dev/nfs-vg/nfs-lv is in fstab] ***************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Make sure /srv/nfs is mounted] *************************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Make sure exportfs accepts LAN] ************************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Restart nfs-kernel-server.service] *********************************
null_resource.ansible: Still creating... [7m0s elapsed]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Re-export the share] ***********************************************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [nfs : Make sure fs structure for ghost data exists] **********************
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): PLAY [deployer] ****************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Create .kube diretory] ********************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Uncompress helm] **************************************
null_resource.ansible: Still creating... [7m10s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Copy helm to /usr/local/bin/helm] *********************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Remove unarchived helm directory] *********************
null_resource.ansible: Still creating... [7m20s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Install pip files] ************************************
null_resource.ansible: Still creating... [7m30s elapsed]
null_resource.ansible: Still creating... [7m40s elapsed]
null_resource.ansible: Still creating... [7m50s elapsed]
null_resource.ansible: Still creating... [8m0s elapsed]
null_resource.ansible: Still creating... [8m10s elapsed]
null_resource.ansible: Still creating... [8m20s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Create directory for secure storing get_keyvault_value script] ***
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [deployment-tools : Copy password obtainer] *******************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): PLAY [kubernetes] **************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible: Still creating... [8m30s elapsed]
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node01]
null_resource.ansible (local-exec): ok: [Node02]

null_resource.ansible (local-exec): TASK [docker : Gather the package facts] ***************************************
null_resource.ansible (local-exec): ok: [Node02]
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): TASK [docker : Download Docker installation script] ****************************
null_resource.ansible: Still creating... [8m40s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [docker : Install Docker] *************************************************
null_resource.ansible: Still creating... [8m50s elapsed]
null_resource.ansible: Still creating... [9m0s elapsed]
null_resource.ansible: Still creating... [9m10s elapsed]
null_resource.ansible: Still creating... [9m20s elapsed]
null_resource.ansible: Still creating... [9m30s elapsed]
null_resource.ansible: Still creating... [9m40s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible: Still creating... [9m50s elapsed]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible: Still creating... [10m0s elapsed]
null_resource.ansible: Still creating... [10m10s elapsed]
null_resource.ansible: Still creating... [10m20s elapsed]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [docker : Enable Docker service] ******************************************
null_resource.ansible: Still creating... [10m30s elapsed]
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node01]
null_resource.ansible (local-exec): ok: [Node02]

null_resource.ansible (local-exec): TASK [docker : Ensure Docker service is running] *******************************
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node01]
null_resource.ansible (local-exec): ok: [Node02]

null_resource.ansible (local-exec): TASK [docker : Remove Docker installation script] ******************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [docker : Add azureuser to docker group] **********************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node02]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [kubernetes : Copy /etc/modprobe.d/k8s.conf] ******************************
null_resource.ansible: Still creating... [10m40s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Add the br_netfilter module] ********************************
null_resource.ansible (local-exec): ok: [Master]
null_resource.ansible (local-exec): ok: [Node01]
null_resource.ansible (local-exec): ok: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Copy /etc/sysctl.d/k8s.conf] ********************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Make sure syctl entries are loaded] *************************
null_resource.ansible (local-exec): changed: [Node02]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible: Still creating... [10m50s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubernetes : Make sure syctl entries are loaded] *************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Add apt key] ************************************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Copy /etc/apt/sources.list.d/kubernetes.list] ***************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node02]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [kubernetes : Update apt repositories cache] ******************************
null_resource.ansible: Still creating... [11m0s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible: Still creating... [11m10s elapsed]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Install Kubernetes] *****************************************
null_resource.ansible: Still creating... [11m20s elapsed]
null_resource.ansible: Still creating... [11m30s elapsed]
null_resource.ansible: Still creating... [11m40s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node01]
null_resource.ansible: Still creating... [11m50s elapsed]
null_resource.ansible: Still creating... [12m0s elapsed]
null_resource.ansible: Still creating... [12m10s elapsed]
null_resource.ansible: Still creating... [12m20s elapsed]
null_resource.ansible (local-exec): changed: [Node02]

null_resource.ansible (local-exec): TASK [kubernetes : Hold kubeadm] ***********************************************
null_resource.ansible (local-exec): changed: [Master] => (item=kubelet)
null_resource.ansible (local-exec): changed: [Node02] => (item=kubelet)
null_resource.ansible (local-exec): changed: [Node01] => (item=kubelet)
null_resource.ansible (local-exec): changed: [Master] => (item=kubeadm)
null_resource.ansible (local-exec): changed: [Node02] => (item=kubeadm)
null_resource.ansible (local-exec): changed: [Node01] => (item=kubeadm)
null_resource.ansible (local-exec): changed: [Master] => (item=kubectl)
null_resource.ansible (local-exec): changed: [Node02] => (item=kubectl)
null_resource.ansible (local-exec): changed: [Node01] => (item=kubectl)

null_resource.ansible (local-exec): TASK [kubernetes : Set bash completion for kubernetes] *************************
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible (local-exec): changed: [Node02]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): PLAY [kubemasters] *************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible: Still creating... [12m30s elapsed]
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Copy rbac.yaml to /tmp/rbac.yaml] **************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Debug kubernetes state before init] ************************
null_resource.ansible (local-exec): fatal: [Master]: FAILED! => {"changed": true, "cmd": "kubectl cluster-info dump", "delta": "0:00:00.133161", "end": "2021-06-21 17:18:49.055081", "msg": "non-zero return code", "rc": 1, "start": "2021-06-21 17:18:48.921920", "stderr": "The connection to the server localhost:8080 was refused - did you specify the right host or port?", "stderr_lines": ["The connection to the server localhost:8080 was refused - did you specify the right host or port?"], "stdout": "", "stdout_lines": []}
null_resource.ansible (local-exec): ...ignoring

null_resource.ansible (local-exec): TASK [kubemasters : Init K8s] **************************************************
null_resource.ansible: Still creating... [12m40s elapsed]
null_resource.ansible: Still creating... [12m50s elapsed]
null_resource.ansible: Still creating... [13m0s elapsed]
null_resource.ansible: Still creating... [13m10s elapsed]
null_resource.ansible: Still creating... [13m20s elapsed]
null_resource.ansible: Still creating... [13m30s elapsed]
null_resource.ansible: Still creating... [13m40s elapsed]
null_resource.ansible: Still creating... [13m50s elapsed]
null_resource.ansible: Still creating... [14m0s elapsed]
null_resource.ansible (local-exec): changed: [Master]
null_resource.ansible: Still creating... [14m10s elapsed]

null_resource.ansible (local-exec): TASK [kubemasters : Create .kube directory] ************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Copy k8s config] *******************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Copy k8s config to local .kube directory] ******************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Get Join command] ******************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Register Join command] *************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Debug join command] ****************************************
null_resource.ansible (local-exec): ok: [Master] => {
null_resource.ansible (local-exec):     "k8sjc.stdout": "kubeadm join 192.168.1.100:6443 --token 34y4kw.6o7ul73ush235vo2 --discovery-token-ca-cert-hash sha256:6da693c005d736b404bcb622af54a10e5f558484fe6abd9caff51146c1cfc933 "
null_resource.ansible (local-exec): }

null_resource.ansible (local-exec): TASK [kubemasters : Download kube-flannel manifest] ****************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Apply flannel manifest to the cluster] *********************
null_resource.ansible: Still creating... [14m20s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Apply RBAC] ************************************************
null_resource.ansible: Still creating... [14m30s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Remove kube-flannel.yml manifest] **************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Remove RBAC] ***********************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Get clusterrolebinding] ************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Create clusterrolebinding] *********************************
null_resource.ansible: Still creating... [14m40s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Get kubernetes node list] **********************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [kubemasters : Register node list] ****************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): PLAY [kubenodes] ***************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible (local-exec): ok: [Node02]
null_resource.ansible (local-exec): ok: [Node01]

null_resource.ansible (local-exec): TASK [kubenodes : Debug ansible_host] ******************************************
null_resource.ansible (local-exec): ok: [Node01] => {
null_resource.ansible (local-exec):     "inventory_hostname": "Node01"
null_resource.ansible (local-exec): }
null_resource.ansible (local-exec): ok: [Node02] => {
null_resource.ansible (local-exec):     "inventory_hostname": "Node02"
null_resource.ansible (local-exec): }

null_resource.ansible (local-exec): TASK [kubenodes : Join Cluster] ************************************************
null_resource.ansible: Still creating... [14m50s elapsed]
null_resource.ansible: Still creating... [15m0s elapsed]
null_resource.ansible (local-exec): changed: [Node02]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): TASK [kubenodes : Create local file system where to store mysql databases] *****
null_resource.ansible (local-exec): skipping: [Node02]
null_resource.ansible (local-exec): changed: [Node01]

null_resource.ansible (local-exec): PLAY [deployer] ****************************************************************

null_resource.ansible (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.ansible: Still creating... [15m10s elapsed]
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ingress-nginx-controller : Create a ingress-basic namespace] *************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ingress-nginx-controller : Add stable chart repo] ************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ingress-nginx-controller : Deploy latest version of ingress-nginx-controller] ***
null_resource.ansible: Still creating... [15m20s elapsed]
null_resource.ansible: Still creating... [15m30s elapsed]
null_resource.ansible: Still creating... [15m40s elapsed]
null_resource.ansible: Still creating... [15m50s elapsed]
null_resource.ansible: Still creating... [16m0s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ingress-nginx-controller : Patch ingress controller] *********************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [cert-manager : Download cert-manager manifest to the cluster.] ***********
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [cert-manager : Apply cert-manager manifest to the cluster.] **************
null_resource.ansible: Still creating... [16m10s elapsed]
null_resource.ansible: Still creating... [16m19s elapsed]
null_resource.ansible: Still creating... [16m29s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [cert-manager : Remove cert-manager manifest from the cluster.] ***********
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [mysql : Label node] ******************************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [mysql : Create a mysql namespace] ****************************************
null_resource.ansible: Still creating... [16m39s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [mysql : Get mysql secret] ************************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [mysql : Register mysql admin password] ***********************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [mysql : Deploy MySQL secrets] ********************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [mysql : Create MySQL service] ********************************************
null_resource.ansible: Still creating... [16m49s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [mysql : Create MySQL deployment] *****************************************
null_resource.ansible: Still creating... [16m59s elapsed]
null_resource.ansible: Still creating... [17m9s elapsed]
null_resource.ansible: Still creating... [17m19s elapsed]
null_resource.ansible: Still creating... [17m29s elapsed]
null_resource.ansible: Still creating... [17m39s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Create a ghost namespace] ****************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Get ghost user secret] *******************************************
null_resource.ansible: Still creating... [17m49s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Get mysql admin password] ****************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Get ghost password secret] ***************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Get ghost database secret] ***************************************
null_resource.ansible: Still creating... [17m59s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Register ghost username] *****************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ghost : Register ghost user password] ************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ghost : Register mysql admin password] ***********************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ghost : Register ghost database] *****************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ghost : Look for MySQL pod name] *****************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ghost : Register Pod name] ***********************************************
null_resource.ansible (local-exec): ok: [Master]

null_resource.ansible (local-exec): TASK [ghost : Create mysql user] ***********************************************
null_resource.ansible: Still creating... [18m9s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Debug user creation] *********************************************
null_resource.ansible (local-exec): ok: [Master] => {
null_resource.ansible (local-exec):     "createuser": {
null_resource.ansible (local-exec):         "changed": true,
null_resource.ansible (local-exec):         "failed": false,
null_resource.ansible (local-exec):         "return_code": 0,
null_resource.ansible (local-exec):         "stderr": "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
null_resource.ansible (local-exec):         "stderr_lines": [
null_resource.ansible (local-exec):             "mysql: [Warning] Using a password on the command line interface can be insecure."
null_resource.ansible (local-exec):         ],
null_resource.ansible (local-exec):         "stdout": "",
null_resource.ansible (local-exec):         "stdout_lines": []
null_resource.ansible (local-exec):     }
null_resource.ansible (local-exec): }

null_resource.ansible (local-exec): TASK [ghost : Create ghost database] *******************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Debug create database] *******************************************
null_resource.ansible (local-exec): ok: [Master] => {
null_resource.ansible (local-exec):     "createdatabase": {
null_resource.ansible (local-exec):         "changed": true,
null_resource.ansible (local-exec):         "failed": false,
null_resource.ansible (local-exec):         "return_code": 0,
null_resource.ansible (local-exec):         "stderr": "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
null_resource.ansible (local-exec):         "stderr_lines": [
null_resource.ansible (local-exec):             "mysql: [Warning] Using a password on the command line interface can be insecure."
null_resource.ansible (local-exec):         ],
null_resource.ansible (local-exec):         "stdout": "",
null_resource.ansible (local-exec):         "stdout_lines": []
null_resource.ansible (local-exec):     }
null_resource.ansible (local-exec): }

null_resource.ansible (local-exec): TASK [ghost : Grant DB permissions] ********************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Debug grant perms] ***********************************************
null_resource.ansible (local-exec): ok: [Master] => {
null_resource.ansible (local-exec):     "grantperms": {
null_resource.ansible (local-exec):         "changed": true,
null_resource.ansible (local-exec):         "failed": false,
null_resource.ansible (local-exec):         "return_code": 0,
null_resource.ansible (local-exec):         "stderr": "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
null_resource.ansible (local-exec):         "stderr_lines": [
null_resource.ansible (local-exec):             "mysql: [Warning] Using a password on the command line interface can be insecure."
null_resource.ansible (local-exec):         ],
null_resource.ansible (local-exec):         "stdout": "",
null_resource.ansible (local-exec):         "stdout_lines": []
null_resource.ansible (local-exec):     }
null_resource.ansible (local-exec): }

null_resource.ansible (local-exec): TASK [ghost : Create tls issuer] ***********************************************
null_resource.ansible: Still creating... [18m19s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Deploy Ghost secrets] ********************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Create Ghost service] ********************************************
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Create Ghost configmap] ******************************************
null_resource.ansible: Still creating... [18m29s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Create Ghost deployment] *****************************************
null_resource.ansible: Still creating... [18m39s elapsed]
null_resource.ansible: Still creating... [18m49s elapsed]
null_resource.ansible: Still creating... [18m59s elapsed]
null_resource.ansible: Still creating... [19m9s elapsed]
null_resource.ansible: Still creating... [19m19s elapsed]
null_resource.ansible: Still creating... [19m29s elapsed]
null_resource.ansible: Still creating... [19m39s elapsed]
null_resource.ansible: Still creating... [19m49s elapsed]
null_resource.ansible: Still creating... [19m59s elapsed]
null_resource.ansible: Still creating... [20m9s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): TASK [ghost : Create Ghost ingress] ********************************************
null_resource.ansible: Still creating... [20m19s elapsed]
null_resource.ansible (local-exec): changed: [Master]

null_resource.ansible (local-exec): PLAY RECAP *********************************************************************
null_resource.ansible (local-exec): Master                     : ok=93   changed=67   unreachable=0    failed=0    skipped=0    rescued=0    ignored=1
null_resource.ansible (local-exec): Node01                     : ok=49   changed=34   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
null_resource.ansible (local-exec): Node02                     : ok=31   changed=20   unreachable=0    failed=0    skipped=1    rescued=0    ignored=0

null_resource.ansible: Creation complete after 20m21s [id=6182467722517468137]

Apply complete! Resources: 35 added, 0 changed, 0 destroyed.

Outputs:

WARNING = ""
ansible_exec_command = "ansible-playbook -i ../ansible/hosts -e jump_host='20.93.250.89' -e admin_user='azureuser' -e subnet_cidr_private='192.168.1.0/24' -e private_lan_master='192.168.1.100' -e private_lan_node01='192.168.1.101' -e private_lan_node02='192.168.1.102' -e internal_private_key_file='~/.ssh/test.pem' -e external_private_key_file='~/.ssh/test.pem' -e ghost_url='ghostmvilla.westeurope.cloudapp.azure.com' ../ansible/playbook.yml"
ghost_http_service_url = "http://ghostmvilla.westeurope.cloudapp.azure.com"
ghost_https_service_url = "https://ghostmvilla.westeurope.cloudapp.azure.com"
master_private_address = "192.168.1.100"
master_public_address = "20.93.250.89"
node01_private_address = "192.168.1.101"
node02_private_address = "192.168.1.102"
ssh_admin_user = "azureuser"
ssh_master_connection = "ssh -i ~/.ssh/test.pem azureuser@20.93.250.89"
ssh_node01_connection = "ssh -i ~/.ssh/test.pem -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ProxyCommand='ssh -i ~/.ssh/test.pem -W %h:%p -q azureuser@20.93.250.89' azureuser@192.168.1.101"
ssh_node02_connection = "ssh -i ~/.ssh/test.pem -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ProxyCommand='ssh -i ~/.ssh/test.pem -W %h:%p -q azureuser@20.93.250.89' azureuser@192.168.1.102"
subnet_cidr_private = tolist([
  "192.168.1.0/24",
])
virtual_network_cidr = tolist([
  "192.168.0.0/16",
])

real	23m56.821s
user	2m29.546s
sys	0m24.003s
